{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 64 # Training set size\n",
    "d_in = 1000 # Dimension of data in\n",
    "h = 100 # Dimension of hiddden layer\n",
    "d_out = 10 # Dimension of data out\n",
    "epochs = 501 # Number of epochs used to train network\n",
    "\n",
    "x = torch.randn(n, d_in, dtype = torch.float, requires_grad = False) # Input tensor\n",
    "y = torch.randn(n, d_out, dtype = torch.float, requires_grad = False)# Output tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:    0 - Loss: 6.29e+02\n",
      "Iteration:   50 - Loss: 3.11e+01\n",
      "Iteration:  100 - Loss: 2.58e+00\n",
      "Iteration:  150 - Loss: 3.15e-01\n",
      "Iteration:  200 - Loss: 4.43e-02\n",
      "Iteration:  250 - Loss: 6.72e-03\n",
      "Iteration:  300 - Loss: 1.08e-03\n",
      "Iteration:  350 - Loss: 1.83e-04\n",
      "Iteration:  400 - Loss: 3.21e-05\n",
      "Iteration:  450 - Loss: 5.84e-06\n",
      "Iteration:  500 - Loss: 1.09e-06\n",
      "Wall time: 586 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Declare overall structure of your neural network in sequence\n",
    "## Linear layers contain tensors for weight and bias\n",
    "### Bias adjusts data by a constant\n",
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(d_in, h),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(h, d_out),\n",
    "        )\n",
    "\n",
    "# Declare your loss function\n",
    "## We are using MSE Loss, using \"reduction = 'sum'\" computes the sum of the squared errors rather than the mean\n",
    "loss_fn = torch.nn.MSELoss(reduction = 'sum')\n",
    "\n",
    "learning_rate = 1e-4 # Higher learning rate with a bias node and better initialized weights\n",
    "for epoch in range(epochs):\n",
    "    y_predict = model(x) # Generate your predictions by calling your model with your data\n",
    "    \n",
    "    loss = loss_fn(y_predict, y) # Calcuate your MSE Loss between your prediction and your actual data by calling your loss function\n",
    "    if not epoch % 50:\n",
    "        print(\"Iteration: %4d - Loss: %0.2e\" % (epoch, loss.item()))\n",
    "        \n",
    "    model.zero_grad() # Calling zero grad on the model will zero all of the tensors in it\n",
    "    \n",
    "    loss.backward() # Run your backpropogation function\n",
    "    \n",
    "    # Update the weights using gradient descent with no autograd since we do not have to keep the gradients on the weights\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param.data -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1000, out_features=100, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 100]         100,100\n",
      "              ReLU-2               [-1, 1, 100]               0\n",
      "            Linear-3                [-1, 1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 101,110\n",
      "Trainable params: 101,110\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.39\n",
      "Estimated Total Size (MB): 0.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    summary(model, input_size = (1, d_in))\n",
    "else:\n",
    "    summary(model.to(torch.device('cuda')), input_size = (1, d_in))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
